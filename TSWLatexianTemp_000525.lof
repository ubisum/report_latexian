\select@language {english}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Three examples of mobile robots: the Nao humanoid robot (a), a robot used for rescuing operations (b) and a quadrotor (c)\relax }}{4}{figure.caption.2}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Hough transform\relax }}{7}{figure.caption.3}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Discrete Hough transform\relax }}{7}{figure.caption.3}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of two possible position hypotheses returned by LINEMATCH\relax }}{11}{figure.caption.4}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Modular representation of full algorithm\relax }}{11}{figure.caption.5}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Original image (a) and extracted features (b), using an acceptance criterion for windows, as explained in 1.30\relax }}{14}{figure.caption.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Ellipses, depicting robot's position error, grow as odometry uncertainty increases\relax }}{20}{figure.caption.7}
\contentsline {figure}{\numberline {3.2}{\ignorespaces The 4x4 meter square path for Borenstein and Koren's method\relax }}{21}{figure.caption.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces The range $\rho $ and the bearing $\theta $, relative to a landmark (line), expressed in robot's reference frame\relax }}{29}{figure.caption.9}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Block representation of a single iteration in $T$ estimation\relax }}{33}{figure.caption.10}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces An example of robot-specific features: the \emph {tf} library, which tracks the position of different elements of robot (sensors, links) in the robot's reference frame\relax }}{35}{figure.caption.11}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Two examples of ROS tools. The \emph {rviz} tool (a) visualizes many common messages provided in ROS, such as laser scans, three-dimensional point clouds and camera images. It also uses information from the \emph {tf} library to show sensor data in a chosen coordinate frame, along with a three-dimensional rendering of robot. The \emph { rqt\_bag} tool (b) records data to bags and can display their content.\relax }}{42}{figure.caption.12}
\contentsline {figure}{\numberline {5.3}{\ignorespaces A \emph {.png} file created for the definition of a map in \emph {Stage}, depicting the first floor of DIAG department\relax }}{43}{figure.caption.13}
\contentsline {figure}{\numberline {5.4}{\ignorespaces A \emph {.world} file relative to Figure 4.3\relax }}{44}{figure.caption.14}
\contentsline {figure}{\numberline {5.5}{\ignorespaces A \emph {.yaml} file relative to Figure 4.3\relax }}{44}{figure.caption.15}
\contentsline {figure}{\numberline {5.6}{\ignorespaces Keyboard commands used by \emph {teleop\_base} controller\relax }}{45}{figure.caption.16}
\contentsline {figure}{\numberline {5.7}{\ignorespaces LSE test 1\relax }}{46}{figure.caption.18}
\contentsline {figure}{\numberline {5.8}{\ignorespaces LSE test 2\relax }}{47}{figure.caption.19}
\contentsline {figure}{\numberline {5.9}{\ignorespaces LSE test 3\relax }}{48}{figure.caption.20}
\contentsline {figure}{\numberline {5.10}{\ignorespaces LSE test 4\relax }}{49}{figure.caption.21}
\contentsline {figure}{\numberline {5.11}{\ignorespaces LSE test 5\relax }}{50}{figure.caption.22}
\contentsline {figure}{\numberline {5.12}{\ignorespaces LSE test 6\relax }}{51}{figure.caption.23}
\contentsline {figure}{\numberline {5.13}{\ignorespaces LSE test 7\relax }}{52}{figure.caption.24}
\contentsline {figure}{\numberline {5.14}{\ignorespaces LSE test 8\relax }}{53}{figure.caption.25}
\contentsline {figure}{\numberline {5.15}{\ignorespaces The lines extracted from $p_1$(red), the ones extracted from $p_2$ (green) and the ones obtained after applying $T_{21}$ to lines in $p_2$ (blue)\relax }}{54}{figure.caption.26}
\contentsline {figure}{\numberline {5.16}{\ignorespaces Lines acquired fron $p_1$ (red) and the ones seen from $p_2$ (green), after applying transformation $T_{21}$ returned by the couples of modules made by LSE and data association\relax }}{54}{figure.caption.27}
\contentsline {figure}{\numberline {5.17}{\ignorespaces Associations between lines seen from $p_1$ (red) and $p_2$'s transformed lines (green). Associations are shown in blue\relax }}{55}{figure.caption.28}
\contentsline {figure}{\numberline {5.18}{\ignorespaces Number of iterations of data association module (X axis) and values of $E_j$ (Y axis)\relax }}{55}{figure.caption.29}
